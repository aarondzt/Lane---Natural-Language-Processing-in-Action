{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Caitlyn Messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 457516\n",
      "total chars: 113\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"gaged. I'm hoping that'll change soon. Thanks for checking in and I'll definitely get back to you on\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = open('Caitlyn - Messages.txt', 'r', encoding = 'utf-8')\n",
    "text = f.read()\n",
    "print('corpus length:', len(text))\n",
    "chars = sorted(list(set(text)))\n",
    "print('total chars:', len(chars))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "text = text.replace(\"\\n\\n\", \" \")\n",
    "text = text.replace(\"\\n\", \" \")\n",
    "text = text.replace(\"------------------------------------------\", \" \")\n",
    "text = text.replace(\"Conversation with Caitlyn\", \" \")\n",
    "text = text.replace(\"Message received from Caitlyn\", \" \")\n",
    "text = text.replace(\"(SMS)\", \" \")\n",
    "text = text.replace(\"(MMS)\", \" \")\n",
    "text = text.replace(\"Message sent\", \" \")\n",
    "text = text.replace(\"AM\", \" \")\n",
    "text = text.replace(\"PM\", \" \")\n",
    "text = text.replace(\"Messages\", \" \")\n",
    "import re\n",
    "text = re.sub(r'http\\S+', '', text)\n",
    "text = re.sub(\"[^A-Za-z.']+\", ' ', text)\n",
    "text = text[3:]\n",
    "text[200:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb sequences: 96038\n"
     ]
    }
   ],
   "source": [
    "# cut the text in semi-redundant sequences of maxlen characters\n",
    "maxlen = 100\n",
    "step = 3\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "print('nb sequences:', len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        X[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 128)               123904    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 113)               14577     \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 113)               0         \n",
      "=================================================================\n",
      "Total params: 138,481\n",
      "Trainable params: 138,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import LSTM\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "# build the model: a single LSTM\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
    "model.add(Dense(len(chars)))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "optimizer = RMSprop(lr = 0.01)\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer=optimizer)\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "batch_size = 128\n",
    "\n",
    "model_structure = model.to_json()\n",
    "with open(\"shakes_lstm_model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_structure)\n",
    "# for i in range(10):\n",
    "#     print('*'*10)\n",
    "#     print('Range ' + str(i + 1) + '/' + str(10))\n",
    "#     print('*'*10)\n",
    "#     model.fit(X, y,\n",
    "#               batch_size = batch_size,\n",
    "#               epochs = epochs)\n",
    "#     model.save_weights(\"shakes_lstm_weights_{}.h5\".format(i+1))\n",
    "#     print('Model saved.')\n",
    "model.load_weights('shakes_lstm_weights_10.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def sample(preds, temperature = 1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'divide': 'warn', 'over': 'warn', 'under': 'ignore', 'invalid': 'warn'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.seterr(divide = 'ignore') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"tired but that's the scaffolding of the first half or so. Serendipity. Did you just write all of tha\"\n",
      "tired but that's the scaffolding of the first half or so. Serendipity. Did you just write all of that I still want to the world and I'm going to be able to the world in the most right. I'm not my sister or almost it's a good thing. I've been a good thing. I'm still a produment is the contine that was that I was pretty says are the stuff I was so working and then I was a bit a couple of your life. I don't know what I can and then there was a good dimpasion that was that I was so say we can do that was a good digh' and then I was so say we can be a good shift it would be a good day. I think I said I really had a good buning and then I get that I was a bit a couple of your sister and the probly is to be a sillen and probably want to the rest of the same way to say that I was so say that I was so working on the sort of me and then there was a bit a couple of your sister I was a bit a course when I get that I was so say so it was so working and a sure of the rest of the start to the perfect of the thing that's what I've been the same thing that's what I've been a lot of a thing. I've been\n",
      "\n",
      "----- diversity: 0.4\n",
      "----- Generating with seed: \"tired but that's the scaffolding of the first half or so. Serendipity. Did you just write all of tha\"\n",
      "tired but that's the scaffolding of the first half or so. Serendipity. Did you just write all of that I've been a good life way to do is that I've got to get that was that I love you the stressf today we can get mom and should be a stuff and I made a good father from the store. I love you soon. I have the end of the long and then I don't have the same way to do that I can can a nice without my count so if you're not find that I could want to pretty sands plased in one and there are you to do that was a failing in the move to the rest of the same is a whole that she was a bad in and then I can wonder to do is here I want to be able to get and then still watching to make your sister on the mad and then me around to the bar sorrook work in the morning. I want to be a couple of your say wheee he as I was so say the produse in the count to the other way to the bar some of sillen be a really into five thing was a bad in the were to wreat Mom in the same was time and then I did the addif I really and there's a bikn like that. It's going to be a good day. I think you've been the princessive \n",
      "\n",
      "----- diversity: 0.6\n",
      "----- Generating with seed: \"tired but that's the scaffolding of the first half or so. Serendipity. Did you just write all of tha\"\n",
      "tired but that's the scaffolding of the first half or so. Serendipity. Did you just write all of that I don't know which is something to the same really can being order some of the total burting for what I had to proper fastical plactial and heard and then there's all the car would be ourself atation in the back to but you've store in the car it and it's am for my brain of I'm not not be has order to go my course in a really go only off it and set of the restuash And see it and care of the world in spective stubling for your radater I've been meet a masoes the night. You're better right than the wor. This is that I said without it probably go a call a little and help there and I was a good live. It the problem was that way to hear that was wonder to time in the car it a lot and you can get in the most and are all all that she was that I've been the pointle to have conscreding to love you too heart of a bar It was not and be a faworking out and experience the perfect oryerable you've watching to see so I was so say from it the contine and I was a prife dum is that way. Is all it to do\n",
      "\n",
      "----- diversity: 0.8\n",
      "----- Generating with seed: \"tired but that's the scaffolding of the first half or so. Serendipity. Did you just write all of tha\"\n",
      "tired but that's the scaffolding of the first half or so. Serendipity. Did you just write all of that It's going to see at addumant than I think that means. I really had I dad or sense I have too long thing I said what I'm going to be went to where haspy I've never feel and in the right. The isentions so I'm fascies and advice. We want your nice of the something to be a usual. Well. I'm systemiclic thing apparently I've said seeff my concogaste lives. And andxgigute person rell I hope I could do it was out the Hisch was bought to be done in my addinn and sens would be and not totally go to be a pend for a good other to deal with me in the continia now I'm hear. May nest pay and I want to chan was like so much me problems so...there's alnoride goes. I've be could to get moving carenalia and truth I can wondirnow are a big too rest of with my fasctical and your . I'd not me. We're trying to do work bad at usentalikestand ducklt. Looking fail. Oh they have a fine of the thing for pretty place attrible your room and I don't believe out. I don't have the Your really in up in the appreciat\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "\n",
    "for diversity in [0.2, 0.4, 0.6, 0.8]:\n",
    "    print()\n",
    "    print('----- diversity:', diversity)\n",
    "\n",
    "    generated = ''\n",
    "    sentence = text[start_index: start_index + maxlen]\n",
    "    generated += sentence\n",
    "    print('----- Generating with seed: \"' + sentence + '\"')\n",
    "    sys.stdout.write(generated)\n",
    "\n",
    "    for i in range(1000):\n",
    "        x = np.zeros((1, maxlen, len(chars)))\n",
    "        for t, char in enumerate(sentence):\n",
    "            x[0, t, char_indices[char]] = 1.\n",
    "\n",
    "        preds = model.predict(x, verbose = 0)[0]\n",
    "        next_index = sample(preds, diversity)\n",
    "        next_char = indices_char[next_index]\n",
    "\n",
    "        generated += next_char\n",
    "        sentence = sentence[1:] + next_char\n",
    "\n",
    "        sys.stdout.write(next_char)\n",
    "        sys.stdout.flush()\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
